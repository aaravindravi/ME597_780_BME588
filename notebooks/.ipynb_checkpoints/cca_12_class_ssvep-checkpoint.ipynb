{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-Class SSVEP Dataset\n",
    "## Classification Using Canonical Correaltion Analysis (CCA)\n",
    "\n",
    "#### Dataset URL: \n",
    "https://github.com/mnakanishi/12JFPM_SSVEP/tree/master/data\n",
    "\n",
    "#### Dataset Paper:\n",
    "Masaki Nakanishi, Yijun Wang, Yu-Te Wang and Tzyy-Ping Jung, \n",
    "\"A Comparison Study of Canonical Correlation Analysis Based Methods for Detecting Steady-State Visual Evoked Potentials,\" \n",
    "PLoS One, vol.10, no.10, e140703, 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scripts import ssvep_utils as su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canonical Correlation Analysis (CCA)\n",
    "$$\\DeclareMathOperator*{\\argmax}{argmax}$$\n",
    "\n",
    "Consider two multidimensional variables $X$, $Y$ where $X$ refers to the set of multi-channel EEG data and $Y$ refers to the set of reference signals of the same length as $X$. The linear combinations of $X$ and $Y$ are given as $x = X'W_{x}$ and $y = Y'W_{y}$. CCA finds the weights, $W_{x}$ and $W_{y}$ that maximize the correlation between $x$ and $y$ by solving (1). The maximum of $\\rho$ with respect to $W_{x}$ and $W_{y}$ is the maximum correlation.\n",
    "\n",
    "$$\\max_{W_{x},W_{y}} \\rho(x,y) = \\frac{\\mathbb{E}{[W_{x}'XY'W_{y}]}}{\\sqrt{\\mathbb{E}{[W_{x}'XX'W_{x}]}\\mathbb{E}{[W_{y}'YY'W_{y}]}}}$$\n",
    "\n",
    "The reference signals $Y_{n}$  are defined as:\n",
    "\n",
    "$$Y_{n} = \\begin{bmatrix} \\sin({2 \\pi f_{n}t}) \\\\ \\cos({2 \\pi f_{n}t}) \\\\ \\vdots \\\\ \\sin({4 \\pi  f_{n}t}) \\\\ \\cos({4 \\pi  f_{n}t}) \\end{bmatrix},t = \\begin{bmatrix} \n",
    "    \\frac{1}{f_{s}}\n",
    "    \\frac{2}{f_{s}}\n",
    "    \\dots\n",
    "    \\frac{N_{s}}{f_{s}}\n",
    "    \\end{bmatrix}$$\n",
    "    \n",
    "where $Y_{n} \\in \\mathbb{R}^{2 N_{h} \\times N_{s}} $, $f_{n}$ is the stimulation frequency, $f_{s}$ is the sampling frequency, $N_{s}$ is number of samples, and $N_{h}$ is the number of harmonics. Here, $N_{h}=2$. The canonical correlation features $\\rho_{f_{i}}$, where $i = 1,2,...,7$ are extracted for each segment of the EEG data, and the output class $C$ for a given sample can be determined as: $C = \\argmax (\\rho_{f_{i}})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('../data')\n",
    "all_segment_data = dict()\n",
    "window_len = 4\n",
    "shift_len = 4\n",
    "sample_rate = 256\n",
    "duration = int(window_len*sample_rate)\n",
    "flicker_freq = np.array([9.25, 11.25, 13.25, 9.75, 11.75, 13.75, \n",
    "                       10.25, 12.25, 14.25, 10.75, 12.75, 14.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cca_reference_signals(data_len, target_freq, sampling_rate):\n",
    "    reference_signals = []\n",
    "    t = np.arange(0, (data_len/(sampling_rate)), step=1.0/(sampling_rate))\n",
    "    reference_signals.append(np.sin(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*2*target_freq*t))\n",
    "    reference_signals.append(np.sin(np.pi*4*target_freq*t))\n",
    "    reference_signals.append(np.cos(np.pi*4*target_freq*t))\n",
    "    reference_signals = np.array(reference_signals)\n",
    "    \n",
    "    return reference_signals\n",
    "\n",
    "def find_correlation(n_components, np_buffer, freq):\n",
    "    cca = CCA(n_components)\n",
    "    corr = np.zeros(n_components)\n",
    "    result = np.zeros(freq.shape[0])\n",
    "    for freq_idx in range(0,freq.shape[0]):\n",
    "        cca.fit(np_buffer.T,np.squeeze(freq[freq_idx, :, :]).T)\n",
    "        O1_a,O1_b = cca.transform(np_buffer.T, np.squeeze(freq[freq_idx, :, :]).T)\n",
    "        ind_val = 0\n",
    "        for ind_val in range(0,n_components):\n",
    "            corr[ind_val] = np.corrcoef(O1_a[: ,ind_val], O1_b[:, ind_val])[0 ,1]\n",
    "            result[freq_idx] = np.max(corr)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def cca_classify(segmented_data, reference_templates):\n",
    "    predicted_class = []\n",
    "    labels = []\n",
    "    for target in range(0, segmented_data.shape[0]):\n",
    "        for trial in range(0, segmented_data.shape[2]):\n",
    "            for segment in range(0, segmented_data.shape[3]):\n",
    "                labels.append(target)\n",
    "                result = find_correlation(1, segmented_data[target, :, trial, segment, :], \n",
    "                                      reference_templates)\n",
    "                predicted_class.append(np.argmax(result)+1)\n",
    "    labels = np.array(labels)+1\n",
    "    predicted_class = np.array(predicted_class)\n",
    "\n",
    "    return labels, predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset, filter and segment epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in np.arange(0, 10):\n",
    "    dataset = sio.loadmat(f'{data_path}/s{subject+1}.mat')\n",
    "    eeg = np.array(dataset['eeg'], dtype='float32')\n",
    "    \n",
    "    num_classes = eeg.shape[0]\n",
    "    n_ch = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "    \n",
    "    filtered_data = su.get_filtered_eeg(eeg, 6, 80, 4, sample_rate)\n",
    "    all_segment_data[f's{subject+1}'] = su.get_segmented_epochs(filtered_data, window_len, \n",
    "                                                           shift_len, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the required sinusoidal templates for the given 12-class SSVEP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_templates = []\n",
    "for fr in range(0, len(flicker_freq)):\n",
    "    reference_templates.append(get_cca_reference_signals(duration, flicker_freq[fr], sample_rate))\n",
    "reference_templates = np.array(reference_templates, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform CCA on the segmented epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: s1, Accuracy: 66.11111111111111 %\n",
      "Subject: s2, Accuracy: 70.55555555555556 %\n",
      "Subject: s3, Accuracy: 98.88888888888889 %\n",
      "Subject: s4, Accuracy: 99.44444444444444 %\n",
      "Subject: s5, Accuracy: 97.77777777777777 %\n",
      "Subject: s6, Accuracy: 100.0 %\n",
      "Subject: s7, Accuracy: 100.0 %\n",
      "Subject: s8, Accuracy: 100.0 %\n",
      "Subject: s9, Accuracy: 98.88888888888889 %\n",
      "Subject: s10, Accuracy: 95.55555555555556 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = dict()\n",
    "for subject in all_segment_data.keys():\n",
    "    labels, predicted_class = cca_classify(all_segment_data[subject], reference_templates)\n",
    "    c_mat = confusion_matrix(labels, predicted_class)\n",
    "    accuracy = np.divide(np.trace(c_mat), np.sum(np.sum(c_mat)))\n",
    "    accuracy_dict[subject] = accuracy*100\n",
    "    print(f'Subject: {subject}, Accuracy: {accuracy*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy Across Subjects: 92.72222222222221 %, std: 12.301385046980446 %\n"
     ]
    }
   ],
   "source": [
    "all_acc = np.array(all_acc)\n",
    "print(f'Overall Accuracy Across Subjects: {np.mean(all_acc)*100} %, std: {np.std(all_acc)*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: These accuracies are reported for the entire 4s duration trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT1ElEQVR4nO3dfbRldX3f8fdHUEGMPM2EIEiHVqJhxaBwRbKoEsFERBNwFRXrw0jASa0oNT5AYpdQU1awtlhNKg0VcawUJUiEGhaUjIDRIjoIAoLKVEGBQcYIqEFCCN/+cTY/L7PuzJy5d87elznv11p3zdkP5/w+nBnO5+69z947VYUkSQBPGDqAJGnxsBQkSY2lIElqLAVJUmMpSJKabYcOsBBLliypZcuWDR1Dkh5Xrr322h9V1dK5lj2uS2HZsmWsXr166BiS9LiS5PYNLXP3kSSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1EysFJJ8PMk9SW6aNW+XJJcnubX7c+dufpJ8JMmaJDck2X9SuSRJGzbJLYVPAIevN+9kYFVV7QOs6qYBXgbs0/2sAM6cYC5J0gZMrBSq6ovAj9ebfSSwsnu8Ejhq1vxP1shXgJ2S7D6pbJKkufV9RvNuVbW2e3w3sFv3eA/gB7PWu6Obt5b1JFnBaGuCvfbaa3JJpS3otNcf3dtY7/3UBXPOv+W0L/SW4dfee+gGl5166qm95ehzrK3FYJe5qKpKstm3fauqs4CzAGZmZrxt3CJ21YsO6W2sQ754VW9jSVuzvkvhh0l2r6q13e6he7r5dwLPmLXent08zcPBf3Zwb2N9+W1f7m0saUs5/y8P7G2sV7/qq72NtSX0/ZXUi4Hl3ePlwEWz5r+x+xbSQcD9s3YzSZJ6MrEthSTnAb8FLElyB3AKcDpwfpLjgNuBV3erXwIcAawBHgCOnVQuTZc/f+f/7m2sE/7L7/Y2ljQpEyuFqnrtBhYdNse6Bbx1UlkkSePxjGZJUmMpSJIaS0GS1Dyub8cpSY9n+11wWW9jfePol461nlsKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJzSClkOQdSb6Z5KYk5yXZLsneSa5JsibJZ5I8aYhskjTNei+FJHsAbwdmqurXgW2AY4APAB+qqmcC9wLH9Z1NkqbdULuPtgW2T7It8BRgLXAocEG3fCVw1DDRJGl69V4KVXUn8J+B7zMqg/uBa4H7qurhbrU7gD3men6SFUlWJ1m9bt26PiJL0tQYYvfRzsCRwN7A04EdgMPHfX5VnVVVM1U1s3Tp0gmllKTpNMTuo5cA36uqdVX1j8CFwMHATt3uJIA9gTsHyCZJU22IUvg+cFCSpyQJcBhwM3AFcHS3znLgogGySdJUG+KYwjWMDih/Hbixy3AWcBLwh0nWALsCZ/edTZKm3babXmXLq6pTgFPWm/1d4MAB4kiSOp7RLElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1g1w6e2v2/fc/p7ex9nrfjb2NJWk6uKUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEnNVnPy2gHv/mRvY137wTf2NpYk9cktBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEnNWKWQ5MIkL09iiUjSVmzcD/mPAv8auDXJ6UmetZBBk+yU5IIk30pyS5LfTLJLksuT3Nr9ufNCxpAkbb6xSqGq/qaqXgfsD9wG/E2S/5vk2CRPnMe4HwYurapnA/sBtwAnA6uqah9gVTctSerR2LuDkuwKvAk4HriO0Qf7/sDlmzNgkh2BFwFnA1TVQ1V1H3AksLJbbSVw1Oa8riRp4ca69lGSvwKeBfxP4Heram236DNJVm/mmHsD64BzkuwHXAucCOw263XvBnbbzNeVJC3QuFsKH6mqfavqT2d9cANQVTObOea2jLYwzqyq5wF/z3q7iqqqgJrryUlWJFmdZPW6des2c2hJ0saMWwr7Jtnp0YkkOyf5t/Mc8w7gjqq6ppu+gFFJ/DDJ7t3r7w7cM9eTq+qsqpqpqpmlS5fOM4IkaS7jlsKbu/3+AFTVvcCb5zNgVd0N/GDWN5gOA24GLgaWd/OWAxfN5/UlSfM37v0UtkmSbrcOSbYBnrSAcd8GnJvkScB3gWMZFdT5SY4DbgdevYDXlyTNw7ilcCmjg8p/0U3/QTdvXqrqemCuYxGHzfc1JUkLN24pnMSoCN7STV8OfGwiiSRJgxmrFKrqEeDM7keStJUa9zyFfYA/BfYFtnt0flX98wnlkiQNYNxvH53DaCvhYeDFwCeBT00qlCRpGOOWwvZVtQpIVd1eVacCL59cLEnSEMY90PwP3WWzb01yAnAn8NTJxZIkDWHcLYUTgacAbwcOAF7PL040kyRtJTa5pdCdqPaaqnoX8DNGJ5pJkrZCm9xSqKp/Av5lD1kkSQMb95jCdUkuBv6S0VVNAaiqCyeSSpI0iHFLYTvg74BDZ80rwFKQpK3IuGc0exxBkqbAuGc0n8McN72pqt/f4okkSYMZd/fR52c93g54JXDXlo8jSRrSuLuPPjt7Osl5wJcmkkiSNJhxT15b3z7AL2/JIJKk4Y17TOGnPPaYwt2M7rEgSdqKjLv76JcmHUSSNLyxdh8leWWSHWdN75TkqImlkiQNYtxjCqdU1f2PTlTVfcApE0kkSRrMuKUw13rjfp1VkvQ4MW4prE5yRpJ/0f2cAVw7yWCSpP6NWwpvAx4CPgN8GngQeOukQkmShjHut4/+Hjh5wlkkSQMb99tHlyfZadb0zkkum1gqSdIgxt19tKT7xhEAVXUvntEsSVudcUvhkSR7PTqRZBlzXDVVkvT4Nu7XSt8LfCnJVUCAFwIrJpZKkjSIcQ80X5pkhlERXAd8Dvj5BHNJkgYw7gXxjgdOBPYErgcOAq7msbfnlCQ9zo17TOFE4PnA7VX1YuB5wH2TCiVJGsa4pfBgVT0IkOTJVfUt4FmTiyVJGsK4B5rv6M5T+BxweZJ7gdsnFUqSNIxxDzS/snt4apIrgB2BSxcycJJtgNXAnVX1iiR7M7qExq6Mrqv0hqp6aCFjSJI2z2bfjrOqrqqqi7fAB/aJwC2zpj8AfKiqngncCxy3wNeXJG2m+d6jeUGS7Am8HPhYNx1G32S6oFtlJXDUENkkaZoNUgrAfwXeAzzSTe8K3FdVD3fTdwB7zPXEJCuSrE6yet26dRMPKknTpPdSSPIK4J6qmtf9GKrqrKqaqaqZpUuXbuF0kjTdhrh72sHA7yU5AtgOeBrwYWCnJNt2Wwt7AncOkE2SplrvWwpV9UdVtWdVLQOOAb5QVa8DrgCO7lZbDlzUdzZJmnZDHVOYy0nAHyZZw+gYw9kD55GkqTPE7qOmqq4Eruwefxc4cMg8kjTtFtOWgiRpYJaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpKb3UkjyjCRXJLk5yTeTnNjN3yXJ5Ulu7f7cue9skjTththSeBh4Z1XtCxwEvDXJvsDJwKqq2gdY1U1LknrUeylU1dqq+nr3+KfALcAewJHAym61lcBRfWeTpGk36DGFJMuA5wHXALtV1dpu0d3Abht4zookq5OsXrduXT9BJWlKDFYKSZ4KfBb4d1X1k9nLqqqAmut5VXVWVc1U1czSpUt7SCpJ02OQUkjyREaFcG5VXdjN/mGS3bvluwP3DJFNkqbZEN8+CnA2cEtVnTFr0cXA8u7xcuCivrNJ0rTbdoAxDwbeANyY5Ppu3h8DpwPnJzkOuB149QDZJGmq9V4KVfUlIBtYfFifWSRJj+UZzZKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqRmUZVCksOTfDvJmiQnD51HkqbNoimFJNsA/w14GbAv8Nok+w6bSpKmy6IpBeBAYE1VfbeqHgI+DRw5cCZJmiqpqqEzAJDkaODwqjq+m34D8IKqOmG99VYAK7rJZwHfXuDQS4AfLfA1FmoxZIDFkWMxZIDFkWMxZIDFkWMxZIDFkWNLZPhnVbV0rgXbLvCFe1dVZwFnbanXS7K6qma21Os9XjMslhyLIcNiybEYMiyWHIshw2LJMekMi2n30Z3AM2ZN79nNkyT1ZDGVwteAfZLsneRJwDHAxQNnkqSpsmh2H1XVw0lOAC4DtgE+XlXf7GHoLbYragEWQwZYHDkWQwZYHDkWQwZYHDkWQwZYHDkmmmHRHGiWJA1vMe0+kiQNzFKQJDVTXwpJTuguq1FJlgyU4dzu8h43Jfl4kicOlOPsJN9IckOSC5I8dYgcXZaPJPnZgON/Isn3klzf/Tx3gAxJclqS7yS5JcnbB8jwt7Peg7uSfK7vDF2Ow5J8vcvxpSTPHCDDoV2Gm5KsTNLbMdkNfU51/0Y+0i27Icn+Cx1r6ksB+DLwEuD2ATOcCzwbeA6wPXD8QDneUVX7VdVvAN8HTtjUEyYhyQyw8xBjr+fdVfXc7uf6AcZ/E6OvaT+7qn6N0Vn+vaqqFz76HgBXAxf2naFzJvC6Lsf/Av59n4MneQKwEjimqn6d0efF8h4jbOhz6mXAPt3PCkbv04JMVSkk2SHJX3e/Dd+U5DVVdV1V3TZwhkuqA3yV0TkaQ+T4SbcsjMppot9CmCtDdw2sDwLvmeTYm8rR19ibyPAW4P1V9QhAVd0zQIZHlz0NOBT43CQzbCRHAU/rVtkRuKvPDMCrgIeq6jvdKpcD/6qPsTfxOXUk8Mnu4+MrwE5Jdl/I+IvmK6k9ORy4q6peDpBkx8WUodtt9AbgxKFyJDkHOAK4GXjnABlOAC6uqrWjburFXDleBpyW5H3AKuDkqvqHnjN8FHhNklcC64C3V9WtPWd41FHAqkd/cZiwuXLcBVyS5OfAT4CDBsjwn5LMVNVq4Ggee7LtpMfekD2AH8yavqObt3a+g0/VlgJwI/DbST6Q5IVVdf8iy/BR4ItV9bdD5aiqY4GnA7cAk/6N+TEZgB0Y/Ub2ZxMed6M5uvfijxjt0ns+sAtw0gAZngw82F3S4H8AHx8gw6NeC5w34fE3luMdwBFVtSdwDnDGABmOAT6U5KvAT4F/6nHs/lTVVP0w+h/89cBVwPtmzb8NWDJUBuAURpvmTxj6veiWvQj4fM8ZTgHu7v4ubgMeYXTl3KHfi98a4L14H/AtYO9uWYD7h3gfGF2A7e+A7fr4u9jAv4v/N2vZXsDNA/+b+B3g/L7HXv9zCvgL4LWzpr8N7L6Qsadq91GSpwM/rqpPJbmPAQ7ozpUhyfHAS4HDqtt/PECONyd5ZlWt6Y4p/B6jD6U+MxxfVb8ya/nPqmri3zLZwN/J7jXahRVGu05u6jsDo18SXgx8DzgE+M4GX2ByGWC0q+TzVfXgJMffSI5/A+yY5FdrtE//txltyfaZ4fgkv1xV9yR5MqMtx9P6Gnsjq18MnJDk08ALGP3iMO9dRzB9xxSeA3wwySPAPwJvyehrfu8BfgW4Ickl1V2+u68MwFcYfavg6m4/+oVV9f4JZpgrx1uBld0BxQDf6LL1mWHS421OjnOTLGX0XlzP6IOp7wxruhzvAH7G5H+J2dDfxzHA6RMee1M5ngF8tpt3L/D7A2R4d5JXMNrtfmZVfaGvsTfyOXUJo2OAa4AHgGMXOriXuZAkNdN2oFmStBGWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0HahCSnJnnXHPOfnuSCeb7mm7qTlDa2zseS7LuB5/75fMaVNmXaTl6TtpiquovR2b7z8SZGZ0lv8GqfEz6JUpqTWwqaSnNdnjjJbeluYJJkJsmVs56yX5Krk9ya5M3dOsu6yyqTZJskH0zytYxudvIHs8Y6KcmN3VinJzkamGF0tvL1SbbfQMYrM7q3BEmOzehmO18FDp7ImyLhloKm11yXJ/7ARtb/DUaXa94BuC7JX6+3/DhG1515fndtnC8n+T+MrrR6JPCCqnogyS5V9eMkJwDvqtFlmDcqo+vj/wfgAOB+4Argus35j5XG5ZaCptXmXp74oqr6eVX9iNGH8oHrLf8d4I1JrgeuAXZldDeslwDnVNUDAFX143lkfQFwZVWtq6qHgM/M4zWksbiloKlUVd/J6H62RwD/Mckq4GF+8YvSdus/ZRPTAd5WVZc9Zmby0i0UWeqFWwqaSt03fx6oqk8xuv3n/oyuVX9At8r6t1o8Msl2SXZldH+Fr623/DJGV7N8Yvf6v5pkB0a3bTw2yVO6+bt06/8U+KUx414DHJJk1+71XzXm86TN5paCptVcl0beHjg7yZ8AV663/g2MdhstAf6kqu5KsoxfbDF8DFgGfL27B8M64KiqujTJc4HVSR5idKnjPwY+Afz3jG4v+ZtV9fMNBe3u63AqcDVwH6NLeUsT4aWzpXlKcgBwRlUdMnQWaUtx95E0D91XRc8DPjx0FmlLcktBGliSvwL2Xm/2SesftJb6YClIkhp3H0mSGktBktRYCpKkxlKQJDX/H7xOlXKB0f+PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame({'subject_id': list(accuracy_dict.keys()), 'accuracy': list(accuracy_dict.values())})\n",
    "sns.barplot(data=accuracy_df, x='subject_id', y='accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "783px",
    "left": "1528px",
    "right": "20px",
    "top": "115px",
    "width": "387px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
